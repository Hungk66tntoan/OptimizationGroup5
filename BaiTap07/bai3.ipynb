{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "def beale_function(x, y):\n",
    "    #f(x_1,x_2) = (1.5 - x_1 + x_1 x_2)^2 + (2.25 - x_1 + x_1 x_2^2)^2 + (2.625 - x_1 + x_1 x_2^3)^2\n",
    "    return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, diff, lambdify\n",
    "class NiceFunction:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.x = sp.Symbol('x')\n",
    "        self.y = sp.Symbol('y')\n",
    "        self.f_x = sp.diff(f(self.x,self.y), self.x)\n",
    "        self.f_x_lamb = sp.lambdify((self.x, self.y), self.f_x, 'numpy')\n",
    "        self.f_y = sp.diff(f(self.x,self.y), self.y)\n",
    "        self.f_y_lamb = sp.lambdify((self.x, self.y), self.f_y, 'numpy')\n",
    "        self.gradient_f_sym = np.array([self.f_x_lamb, self.f_y_lamb])\n",
    "        self.f_xx = sp.diff(self.f_x, self.x)\n",
    "        self.f_xx_lamb = sp.lambdify((self.x, self.y), self.f_xx, 'numpy')\n",
    "        self.f_yy = sp.diff(self.f_y, self.y)\n",
    "        self.f_yy_lamb = sp.lambdify((self.x, self.y), self.f_yy, 'numpy')\n",
    "        self.f_xy = sp.diff(self.f_x, self.y)\n",
    "        self.f_xy_lamb = sp.lambdify((self.x, self.y), self.f_xy, 'numpy')\n",
    "        self.f_yx = sp.diff(self.f_y, self.x)\n",
    "        self.f_yx_lamb = sp.lambdify((self.x, self.y), self.f_yx, 'numpy')\n",
    "        self.hessian_f_lamb = np.array([[self.f_xx_lamb, self.f_xy_lamb],\n",
    "                                        [self.f_yx_lamb, self.f_yy_lamb]])\n",
    "    def gradient_f(self, val_x, val_y):\n",
    "        #thay số vào đạo hàm\n",
    "        ans = np.array([0.0,0.0])\n",
    "        ans[0] = self.f_x_lamb(val_x, val_y)\n",
    "        ans[1] = self.f_y_lamb(val_x, val_y)\n",
    "        return ans\n",
    "\n",
    "    def hessian_f(self, val_x, val_y):\n",
    "        ans = np.array([[0.0,0.0],[0.0,0.0]])\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ans[i][j] += self.hessian_f_lamb[i][j](val_x, val_y)\n",
    "        return ans\n",
    "                 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function beale_function at 0x0000021B1FB816C0>\n",
      "[<function _lambdifygenerated at 0x0000021B1FB16FC0>\n",
      " <function _lambdifygenerated at 0x0000021B1FB80A40>]\n",
      "[[ 1488.    7691.75]\n",
      " [ 7691.75 15883.75]]\n"
     ]
    }
   ],
   "source": [
    "niceFunction = NiceFunction(beale_function)\n",
    "print(niceFunction.f)\n",
    "print(niceFunction.gradient_f_sym)\n",
    "print(niceFunction.hessian_f(2.5,3))\n",
    "#print(niceFunction.hessian_f_sym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.75\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, lambdify\n",
    "\n",
    "# Define the function f(x)\n",
    "x = symbols('x')\n",
    "f = x**2 + 2*x - 1\n",
    "\n",
    "# Compute the derivative of f(x)\n",
    "df = diff(f, x)\n",
    "\n",
    "# Create a lambda function from f(x) and df/dx\n",
    "f_lam = lambdify(x, f, 'numpy')\n",
    "df_lam = lambdify(x, df, 'numpy')\n",
    "\n",
    "# Evaluate the derivative at x = 2\n",
    "x_val = 2.375\n",
    "df_val = df_lam(x_val)\n",
    "\n",
    "print(df_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.196 9.196\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, lambdify\n",
    "from sympy.abc import x, y\n",
    "\n",
    "# Define the function f(x, y)\n",
    "f = x**2 + 2*x*y + y**2\n",
    "\n",
    "# Compute the partial derivatives of f(x, y)\n",
    "df_dx = diff(f, x)\n",
    "df_dy = diff(f, y)\n",
    "\n",
    "# Create a lambda function from f(x, y), df/dx and df/dy\n",
    "f_lam = lambdify((x, y), f, 'numpy')\n",
    "df_dx_lam = lambdify((x, y), df_dx, 'numpy')\n",
    "df_dy_lam = lambdify((x, y), df_dy, 'numpy')\n",
    "\n",
    "# Evaluate the partial derivatives at (x, y) = (1, 2)\n",
    "x_val = 1.7\n",
    "y_val = 2.898\n",
    "df_dx_val = df_dx_lam(x_val, y_val)\n",
    "df_dy_val = df_dy_lam(x_val, y_val)\n",
    "\n",
    "print(df_dx_val, df_dy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function trial_function at 0x0000021B1FB17920>\n",
      "[<function _lambdifygenerated at 0x0000021B1FB81620>\n",
      " <function _lambdifygenerated at 0x0000021B1FB805E0>]\n",
      "[[<function _lambdifygenerated at 0x0000021B1FB80180>\n",
      "  <function _lambdifygenerated at 0x0000021B1FB167A0>]\n",
      " [<function _lambdifygenerated at 0x0000021B1FB16E80>\n",
      "  <function _lambdifygenerated at 0x0000021B1FB823E0>]]\n"
     ]
    }
   ],
   "source": [
    "def trial_function(x,y):\n",
    "    return (x+y)**2 + y**3 + x*y\n",
    "nice_trial_function = NiceFunction(trial_function)\n",
    "print(nice_trial_function.f)\n",
    "print(nice_trial_function.gradient_f_sym)\n",
    "print(nice_trial_function.hessian_f_lamb)\n",
    "#thay số vào hàm trong sympy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewtonFindMin:\n",
    "    def __init__(self, niceFunction, x0, epsilon=1e-4, max_iterations=1000,\n",
    "                 alpha = 1,\n",
    "                 shrinking_factor = 0.5,\n",
    "                 beta = 0.5,):\n",
    "        self.niceFunction = niceFunction\n",
    "        self.x0 = x0\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iterations = max_iterations\n",
    "        self.alpha = alpha\n",
    "        self.shrinking_factor = shrinking_factor\n",
    "        self.beta = beta\n",
    "        \n",
    "    def gradient_descent_backtracking_linesearch(self, contraction_factor=0.5):\n",
    "        x = self.x0[0]\n",
    "        y = self.x0[1]\n",
    "        for i in range(self.max_iterations):\n",
    "            currentGrad_f = self.niceFunction.gradient_f(x, y)\n",
    "            # Tinh do dai buoc t_k.\n",
    "            t_Initital = self.alpha\n",
    "            while (self.niceFunction. f(x - t_Initital * currentGrad_f[0],\n",
    "                                       y - t_Initital * currentGrad_f[1])>\n",
    "                   self.niceFunction.f(x, y) - self.beta * t_Initital * \n",
    "                   np.linalg.norm(currentGrad_f)**2):\n",
    "                t_Initital = t_Initital * contraction_factor\n",
    "            # Tinh x_k\n",
    "            x = x - t_Initital * currentGrad_f[0]\n",
    "            y = y - t_Initital * currentGrad_f[1]\n",
    "\n",
    "            # Dieu kien dung epsilon.\n",
    "            if np.linalg.norm(currentGrad_f) <= self.epsilon:\n",
    "                break\n",
    "        return x, y\n",
    "    def newton_backtracking_linesearch(self, contraction_factor=0.5):\n",
    "        x = self.x0[0]\n",
    "        y = self.x0[1]\n",
    "        for i in range(self.max_iterations):\n",
    "            current_gradient = self.niceFunction.gradient_f(x, y)\n",
    "            t = self.alpha\n",
    "            if np.linalg.norm(current_gradient) < self.epsilon:\n",
    "                break\n",
    "            current_hess = self.niceFunction.hessian_f(x, y)\n",
    "            v = -np.linalg.solve(current_hess, current_gradient)\n",
    "            h= v@current_gradient\n",
    "            for j in range(self.max_iterations):\n",
    "                next_x = x + t * v[0]\n",
    "                next_y = y + t* v[1]\n",
    "                if (self.niceFunction.f(next_x, next_y) > \n",
    "                    self.niceFunction.f(x, y) + self.beta *t* h):\n",
    "                    t = t*contraction_factor\n",
    "                else:\n",
    "                    x = next_x\n",
    "                    y = next_y\n",
    "                    break\n",
    "        return x, y \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.999744002288866, 0.49993905700308955)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0641621205175453e-08"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice_beale_function = NiceFunction(beale_function)\n",
    "A = np.array([0,0])\n",
    "B = np.array([-4,3])\n",
    "newtonSolver = NewtonFindMin(nice_beale_function, A)\n",
    "sol1 = newtonSolver.gradient_descent_backtracking_linesearch()\n",
    "print(sol1)\n",
    "beale_function(sol1[0], sol1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-3.9624363645907943, 1.2077242794125627)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7997832555733841"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtonSolverB = NewtonFindMin(nice_beale_function, B)\n",
    "sol2 = newtonSolverB.gradient_descent_backtracking_linesearch()\n",
    "print(sol2)\n",
    "beale_function(sol2[0], sol2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.784384649436178e-23, 1.0000010840435472)\n",
      "14.203125\n",
      "[3.00822322e-05 1.88266972e-21]\n"
     ]
    }
   ],
   "source": [
    "sol3 = newtonSolver.newton_backtracking_linesearch()\n",
    "print(sol3)\n",
    "print(beale_function(sol3[0], sol3[1]))\n",
    "#in đạo hàm\n",
    "print(nice_beale_function.gradient_f(sol3[0], sol3[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.312493982989568, 1.5060303115585763)\n",
      "1.339453526906003\n",
      "[-0.30609825  2.92488336]\n"
     ]
    }
   ],
   "source": [
    "sol4 = newtonSolverB.newton_backtracking_linesearch()\n",
    "print(sol4)\n",
    "print(beale_function(sol4[0], sol4[1]))\n",
    "print(nice_beale_function.gradient_f(sol4[0], sol4[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beale_function(0,1)\n",
    "nice_beale_function.gradient_f(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
